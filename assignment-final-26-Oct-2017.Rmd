---
title: "Prediction Assignment Writeup"
author: "Ranjan Vaidya"
date: "26 October 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Downloading the dataset.

In this step, the data gets downloaded as a data frame. two datasets namely training data and testing data are downloaded. The training data is used for model training and the testing data for predictions.

```{r download}
training <- as.data.frame(read.table("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", sep=",", header=T))
str(training)
testing <- as.data.frame(read.table("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", sep=",", header=T))
str(testing)
```

## Preprocessing the training dataset

In this step, the training data is processed for model building. The nominal variables are removed, and also the variables with near zero variaances and many missing values are removed step-by-step.

```{r preprocessing-training-data}
library(caret)
nsv <- nearZeroVar(training,saveMetrics=TRUE)
training <- training[, nsv$nzv == FALSE]
training <- training[, -c(1:6)]
str(training)
library(dplyr)
training <- select(training, -c(max_roll_belt:var_yaw_belt))
training <- select(training, -c(max_picth_arm:amplitude_yaw_arm))
training <- select(training, -c(max_roll_dumbbell: amplitude_pitch_dumbbell))
training <- select(training, -c(var_accel_dumbbell: var_yaw_dumbbell))
training <- select(training, -c(max_picth_forearm: amplitude_pitch_forearm))
str(training)
training <- select(training, -c(var_accel_arm, var_accel_forearm))
str(training)
```

## Preprocessing the testing dataset

In this step, the testing data is processed for predictions. The nominal variables are removed, and also the variables with near zero variaances and many missing values are removed.

```{r preprocessing-testing-data}
nsv <- nearZeroVar(testing,saveMetrics=TRUE)
testing <- testing[, nsv$nzv == FALSE]
testing <- testing[, -c(1:6)]
str(testing)
```

## Creating the data partition

In this step, the training data is partitioned into a training and a validating dataset. This is done so that the trained model can be validated for accuracy levels. Since the testing data does not have an outcome variable 'classe', it is important to have a validating data for assessing the accuracy of the model. The model that is highest in accuracy is most suitable predictor model, and will be used for answering the quiz questions.

```{r data partition}
library(caret)
set.seed(10000)
inTrain <- createDataPartition(y=training$classe, p=0.7, list=FALSE)
training <- training[inTrain,]
validating <- training[-inTrain,]
dim(training); dim(validating)
```

## Predicting with classification tree

In this step, a classification tree is used for making predictions. First a model is developed using training data, it is then validated on the validating data. Finally the model is used for predictions (by deplying it on the testing data). The results of the prediction categories are presented. The tree based model has a low accuracy of 0.49.

```{r classification-tree}
modFit <- train(classe ~ .,method="rpart",data=training)
prediction_tree <- predict(modFit,newdata=validating)
confusionMatrix(prediction_tree, validating$classe)
print(modFit$finalModel)
plot(modFit$finalModel, uniform=TRUE, main="Classification Tree")
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
tree_based_prediction <- predict(modFit,newdata=testing)
tree_based_prediction
```

## Predicting with linear discriminant analysis

In this step, discriminant analysis is used for making predictions. First a model is developed using training data, it is then validated on the validating data. Finally the model is used for predictions (by deplying it on the testing data). The results of the prediction categories are presented. The discriminant analysis based model has a higher  accuracy than tree based model (0.70).

```{r LDA}
library(klaR)
set.seed(20000)
modlda = train(classe ~ .,data=training,method="lda")
validating_LDA <- predict(modlda,validating)
confusionMatrix(validating_LDA, validating$classe)
plda = predict(modlda,testing)
plda
```

## Predicting with random forest

In this step, random forest technique is used for making predictions. First a model is developed using training data, it is then validated on the validating data. Finally the model is used for predictions (by deplying it on the testing data). The results of the prediction categories are presented. The random forest based model has the highest accuracy than both the tree based model and discriminant analysis. In fact the accuracy level is nearly 100 percent.

```{r random-forest}
library(randomForest)
set.seed(30000)
modFit_RF <- randomForest(classe ~ ., data=training)
validating_RF <- predict(modFit_RF, validating)
confusionMatrix(validating_RF, validating$classe)
prediction_RF <- predict(modFit_RF, testing)
prediction_RF
```
